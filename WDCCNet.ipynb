{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import sys\n",
    "import difflib\n",
    "import numpy as np\n",
    "import random\n",
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.nn import Parameter\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = '../../datasets/CBIS/train_all.txt'\n",
    "file2 = '../../datasets/CBIS/test_all.txt'\n",
    "f1 = open(file1, 'r')\n",
    "f2 = open(file2, 'r')\n",
    "data_train = f1.readlines()\n",
    "data_test = f2.readlines()\n",
    "def get_data(data):\n",
    "    out_data = []\n",
    "    out_label = []\n",
    "    count = 0\n",
    "    for line in data:\n",
    "        name = line.split(',')[0]\n",
    "        if 'BENIGN' in line:\n",
    "            label = 0\n",
    "        elif 'MALIGNANT' in line:\n",
    "            label = 1\n",
    "        out_data.append(name)\n",
    "        out_label.append(label)\n",
    "    return out_data, out_label\n",
    "train_list, train_label_list = get_data(data_train)\n",
    "test_list, test_label_list = get_data(data_test)\n",
    "f1.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedDoubleClassifier(nn.Module):\n",
    "    def __init__(self, in_features, out_features, n=2):\n",
    "        super(WeightedDoubleClassifier, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n = n\n",
    "        self.base = 1000.0\n",
    "        self.iter = 0\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    \n",
    "    def forward(self, input, label):\n",
    "        self.iter += 1\n",
    "\n",
    "        cos_theta = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        cos_theta = cos_theta.clamp(-1, 1)\n",
    "        theta = cos_theta.data.acos()\n",
    "\n",
    "        phi1 = torch.cat([cos_theta[:,0].view(-1,1)*self.n, cos_theta[:,1].view(-1,1)],dim=1)\n",
    "        phi2 = torch.cat([cos_theta[:,0].view(-1,1), cos_theta[:,1].view(-1,1)*self.n,],dim=1)\n",
    "        output1 =  phi1 * torch.norm(input, 2, 1).view(-1, 1)\n",
    "        output2 = phi2 * torch.norm(input, 2, 1).view(-1, 1)\n",
    "        output_std = cos_theta * torch.norm(input, 2, 1).view(-1, 1)\n",
    "        return output1, output2, output_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../../datasets/CBIS/images/'\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, labels_df, img_path, transform=None):\n",
    "        self.labels_df = labels_df\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # import pdb;pdb.set_trace()\n",
    "        img = Image.open(self.img_path + self.labels_df.path[idx] + '.png')\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        label = np.array(self.labels_df.lab[idx],'float')\n",
    "        \n",
    "        return img, label\n",
    "train_transforms = transforms.Compose([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.2),\n",
    "                                       transforms.Resize((820,820)),\n",
    "                                      transforms.RandomCrop((800,800)),\n",
    "                                      transforms.RandomRotation(30),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # 0.485, 0.456, 0.406; 0.229, 0.224, 0.225\n",
    "test_transforms = transforms.Compose([transforms.Resize([800,800]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "image_transforms = {'train':train_transforms, 'test':test_transforms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "class CNN(nn.Module): \n",
    "    def __init__(self, model):\n",
    "        super(CNN, self).__init__()\n",
    "        self.resnet_layer = nn.Sequential(*list(model.children())[:-1])\n",
    "        self.avp_pooling = nn.AdaptiveAvgPool2d((1, 1)) # AdaptiveAvgPool2d\n",
    "        self.linear_layer1 = nn.Linear(1024, 1024) #  * 1024\n",
    "        self.linear_layer2 = WeightedDoubleClassifier(1024, 2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, label):\n",
    "        x = self.resnet_layer(x)\n",
    "        x = self.avp_pooling(x).view(x.size()[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.linear_layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x1, x2, x_std = self.linear_layer2(x, label)\n",
    "\n",
    "        return x1, x2, x_std # sf\n",
    "\n",
    "def weight_loss(output1, output2, label):\n",
    "    loss1 = 0.\n",
    "    loss2 = 0.\n",
    "    pred1 = output1.argmax(dim=1, keepdim = True)\n",
    "    pred2 = output2.argmax(dim=1, keepdim = True)\n",
    "    for i in range(len(pred1)): # \n",
    "        if pred1[i] == pred2[i]:\n",
    "            loss1 += -label[i] * torch.log_softmax(output1[i], -1)[1]-(1-label[i]) * torch.log_softmax(output1[i], -1)[0]  #+ 1e-10\n",
    "            loss2 += -label[i] * torch.log_softmax(output2[i], -1)[1]-(1-label[i]) * torch.log_softmax(output2[i], -1)[0]\n",
    "        else:\n",
    "            alpha_weight = 2. - torch.abs(torch.softmax(output1[i], -1)[1]-torch.softmax(output2[i], -1)[1])\n",
    "            if label[i] == pred2[i]:\n",
    "                loss1 += (-label[i] * torch.log_softmax(output1[i], -1)[1]-(1-label[i]) * torch.log_softmax(output1[i], -1)[0]) * alpha_weight\n",
    "            else:\n",
    "                loss2 += (-label[i] * torch.log_softmax(output2[i], -1)[1]-(1-label[i]) * torch.log_softmax(output2[i], -1)[0]) * alpha_weight \n",
    "    return loss1/len(pred1), loss2/len(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, dataloader, epoch, set_name='test'):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    output_all = []\n",
    "    output_all1 = []\n",
    "    output_all_std = []\n",
    "    label = []\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(dataloader):\n",
    "            X, y = data\n",
    "            label.extend(y)\n",
    "            # print(y)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device, dtype=torch.int64)\n",
    "            _, _, output_std = model(X, y)\n",
    "            output_std = torch.nn.Softmax(dim=-1)(output_std)\n",
    "            output_all_std.extend(torch.nn.Softmax(dim=-1)(output_std).cpu().detach().numpy())\n",
    "    if set_name == 'test':\n",
    "        test_loss /= (len(label)//batch_size)  \n",
    "        acc_std = accuracy_score(label, np.argmax(output_all_std, -1))\n",
    "        auc_std = roc_auc_score(label, np.array(output_all_std)[:,1])\n",
    "        # print(confusion_matrix(label, np.argmax(output_all_std, -1)), acc_std, auc_std)\n",
    "        return auc_std# acc, auc, output_all\n",
    "\n",
  
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "date_file = str(now.year) + '_' + str(now.month) + '_' + str(now.day)\n",
    "print(str(now.year) + '_' + str(now.month) + '_' + str(now.day))\n",
    "\n",
    "base_model = models.densenet121(pretrained=True)\n",
    "cnn = CNN(base_model).to(device)\n",
    "cnn.load_state_dict(torch.load('./models/_2021_5_20_wdcc1_0_DenseNet-121_1.pth', map_location=device)) \n",
    "test_X, test_y = np.array(test_list), np.array(test_label_list)\n",
    "\n",
    "batch_size = 12\n",
    "test1 = list(zip(test_X, list(test_y)))\n",
    "test_df= pd.DataFrame(test1, columns=['path','lab'])\n",
    "test_dataset = MyDataset(test_df, image_path, transform=image_transforms['test'])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=6)\n",
    "\n",
    "print(\"--------------Begin test--------------\")\n",
    "auc = test(cnn, device, testloader, 1, set_name = 'test')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
